{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from util.data_management import concate_data, load_data_raw, display_data, data_to_fft, data_adjust_scale, data_reshape_for_train, data_split_to_chunk\n",
    "from util.data_generator_AE import DataGenerator\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from sklearn import metrics\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = EasyDict({\n",
    "    'dir_path' : r\"D:\\Anomaly-Dataset\", ## 1: C:\\Users\\VIP444\\Documents\\Anomaly-Dataset, 2: D:\\Anomaly-Dataset\\sar400_vibration_data\n",
    "    'is_normal' : True,\n",
    "    'is_train' : True,\n",
    "    'stop_idx' : 2,\n",
    "    'data_scale_fit' : True,\n",
    "    'data_scale_trans' : False,\n",
    "    'batch_size' : 512,\n",
    "    'split' : (0.9, 0.1),\n",
    "    'is_cache' : True,\n",
    "    'is_normalize' : False,\n",
    "    'is_lstm' : True\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataGenerator(\n",
    "    dataset_path=args.dir_path,\n",
    "    train_mode='Train',\n",
    "    batch_size=args.batch_size,\n",
    "    split=args.split,\n",
    "    is_train=args.is_train,\n",
    "    is_cache=args.is_cache,\n",
    "    is_normalize=args.is_normalize,\n",
    "    is_lstm=args.is_lstm\n",
    ")\n",
    "\n",
    "validation_dataset = DataGenerator(\n",
    "    dataset_path=args.dir_path,\n",
    "    train_mode='Validation',\n",
    "    batch_size=args.batch_size,\n",
    "    split=args.split,\n",
    "    is_train=args.is_train,\n",
    "    is_cache=args.is_cache,\n",
    "    is_normalize=args.is_normalize,\n",
    "    is_lstm=args.is_lstm\n",
    ")\n",
    "\n",
    "test_dataset = DataGenerator(\n",
    "    dataset_path=args.dir_path,\n",
    "    train_mode='Test',\n",
    "    batch_size=args.batch_size,\n",
    "    split=args.split,\n",
    "    is_train=False,\n",
    "    is_cache=args.is_cache,\n",
    "    is_normalize=args.is_normalize,\n",
    "    is_lstm=args.is_lstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7034\n",
      "782\n",
      "4276\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset.data_paths))\n",
    "print(len(validation_dataset.data_paths))\n",
    "print(len(test_dataset.data_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_0, train_data_1, train_data_2, train_data_3, validation_data_0, validation_data_1, validation_data_2, validation_data_3 = load_data_raw(\n",
    "    dir_path=args.dir_path, \n",
    "    is_normal=args.is_normal, \n",
    "    is_train=args.is_train, \n",
    "    stop_idx=args.stop_idx\n",
    "    )\n",
    "\n",
    "test_data_0, test_data_1, test_data_2, test_data_3 = load_data_raw(\n",
    "    dir_path=args.dir_path,\n",
    "    is_normal=False,\n",
    "    is_train=False,\n",
    "    stop_idx=args.stop_idx\n",
    ")\n",
    "\n",
    "display_data(train_data_0, validation_data_0, test_data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "train_data_0 = train_data_0[:len(test_data_0)]\n",
    "\n",
    "x = pd.DataFrame({\n",
    "    'x1': train_data_0.squeeze(-1),\n",
    "    'x2': test_data_0.squeeze(-1),\n",
    "    })\n",
    "\n",
    "scaler = RobustScaler()\n",
    "robust_df = scaler.fit_transform(x)\n",
    "robust_df = pd.DataFrame(robust_df, columns =['x1', 'x2'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "standard_df = scaler.fit_transform(x)\n",
    "standard_df = pd.DataFrame(standard_df, columns =['x1', 'x2'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "minmax_df = scaler.fit_transform(x)\n",
    "minmax_df = pd.DataFrame(minmax_df, columns =['x1', 'x2'])\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols = 4, figsize =(20, 5))\n",
    "ax1.set_title('Before Scaling')\n",
    "\n",
    "sns.kdeplot(x['x1'], ax = ax1, color ='r')\n",
    "sns.kdeplot(x['x2'], ax = ax1, color ='b')\n",
    "ax2.set_title('Robust Scaling')\n",
    "\n",
    "sns.kdeplot(robust_df['x1'], ax = ax2, color ='red')\n",
    "sns.kdeplot(robust_df['x2'], ax = ax2, color ='blue')\n",
    "ax3.set_title('Standard Scaling')\n",
    "\n",
    "sns.kdeplot(standard_df['x1'], ax = ax3, color ='black')\n",
    "sns.kdeplot(standard_df['x2'], ax = ax3, color ='g')\n",
    "ax4.set_title('Min-Max Scaling')\n",
    "\n",
    "sns.kdeplot(minmax_df['x1'], ax = ax4, color ='black')\n",
    "sns.kdeplot(minmax_df['x2'], ax = ax4, color ='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('Scaler', StandardScaler())])\n",
    "\n",
    "X_train_0 = data_adjust_scale(pipeline, train_data_0, args.data_scale_fit)\n",
    "X_train_1 = data_adjust_scale(pipeline, train_data_1, args.data_scale_trans)\n",
    "X_train_2 = data_adjust_scale(pipeline, train_data_2, args.data_scale_trans)\n",
    "X_train_3 = data_adjust_scale(pipeline, train_data_3, args.data_scale_trans)\n",
    "\n",
    "X_validation_0 = data_adjust_scale(pipeline, validation_data_0, args.data_scale_trans)\n",
    "X_validation_1 = data_adjust_scale(pipeline, validation_data_1, args.data_scale_trans)\n",
    "X_validation_2 = data_adjust_scale(pipeline, validation_data_2, args.data_scale_trans)\n",
    "X_validation_3 = data_adjust_scale(pipeline, validation_data_3, args.data_scale_trans)\n",
    "\n",
    "X_test_0 = data_adjust_scale(pipeline, test_data_0, args.data_scale_trans)\n",
    "X_test_1 = data_adjust_scale(pipeline, test_data_1, args.data_scale_trans)\n",
    "X_test_2 = data_adjust_scale(pipeline, test_data_2, args.data_scale_trans)\n",
    "X_test_3 = data_adjust_scale(pipeline, test_data_3, args.data_scale_trans)\n",
    "\n",
    "display_data(X_train_0, X_validation_0, X_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = concate_data((X_train_0, X_train_1, X_train_2, X_train_3), 1)\n",
    "X_validation = concate_data((X_validation_0, X_validation_1, X_validation_2, X_validation_3), 1)\n",
    "X_test = concate_data((X_test_0, X_test_1, X_test_2, X_test_3), 1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train = data_reshape_for_train(X_train_0, X_train_1, X_train_2, X_train_3)\n",
    "X_validation = data_reshape_for_train(X_validation_0, X_validation_1, X_validation_2, X_validation_3)\n",
    "X_test = data_reshape_for_train(X_test_0, X_test_1, X_test_2, X_test_3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1, 4)]            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 64)             17664     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 1, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 1, 64)             24832     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 1, 4)              260       \n",
      "=================================================================\n",
      "Total params: 63,492\n",
      "Trainable params: 63,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from models.ae_LSTM import autoencoder_model\n",
    "# from models.ae_Dense import autoencoder_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Huber\n",
    "\n",
    "if args.is_lstm:\n",
    "    input_shape = (1, 4)\n",
    "else:\n",
    "    input_shape = (4, )\n",
    "\n",
    "model = autoencoder_model(input_shape)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss=Huber(), metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "13/13 [==============================] - 2s 48ms/step - loss: 1.0395 - mae: 1.4401 - val_loss: 1.3687 - val_mae: 1.7858\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 1.78582, saving model to model\\checkpoint.pt\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 1.0239 - mae: 1.4193 - val_loss: 1.3493 - val_mae: 1.7614\n",
      "\n",
      "Epoch 00002: val_mae improved from 1.78582 to 1.76136, saving model to model\\checkpoint.pt\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 1.0018 - mae: 1.3904 - val_loss: 1.3151 - val_mae: 1.7192\n",
      "\n",
      "Epoch 00003: val_mae improved from 1.76136 to 1.71922, saving model to model\\checkpoint.pt\n",
      "Epoch 4/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.9553 - mae: 1.3321 - val_loss: 1.2010 - val_mae: 1.5842\n",
      "\n",
      "Epoch 00004: val_mae improved from 1.71922 to 1.58422, saving model to model\\checkpoint.pt\n",
      "Epoch 5/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.7633 - mae: 1.1059 - val_loss: 0.9162 - val_mae: 1.2896\n",
      "\n",
      "Epoch 00005: val_mae improved from 1.58422 to 1.28960, saving model to model\\checkpoint.pt\n",
      "Epoch 6/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.5302 - mae: 0.8512 - val_loss: 0.6479 - val_mae: 1.0015\n",
      "\n",
      "Epoch 00006: val_mae improved from 1.28960 to 1.00146, saving model to model\\checkpoint.pt\n",
      "Epoch 7/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.3902 - mae: 0.6963 - val_loss: 0.6171 - val_mae: 1.0043\n",
      "\n",
      "Epoch 00007: val_mae did not improve from 1.00146\n",
      "Epoch 8/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2623 - mae: 0.5579 - val_loss: 0.4944 - val_mae: 0.8597\n",
      "\n",
      "Epoch 00008: val_mae improved from 1.00146 to 0.85973, saving model to model\\checkpoint.pt\n",
      "Epoch 9/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1767 - mae: 0.4707 - val_loss: 0.3391 - val_mae: 0.6668\n",
      "\n",
      "Epoch 00009: val_mae improved from 0.85973 to 0.66676, saving model to model\\checkpoint.pt\n",
      "Epoch 10/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1331 - mae: 0.4229 - val_loss: 0.2950 - val_mae: 0.6455\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.66676 to 0.64554, saving model to model\\checkpoint.pt\n",
      "Epoch 11/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1180 - mae: 0.3976 - val_loss: 0.2911 - val_mae: 0.6641\n",
      "\n",
      "Epoch 00011: val_mae did not improve from 0.64554\n",
      "Epoch 12/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1157 - mae: 0.3823 - val_loss: 0.2897 - val_mae: 0.6672\n",
      "\n",
      "Epoch 00012: val_mae did not improve from 0.64554\n",
      "Epoch 13/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1151 - mae: 0.3777 - val_loss: 0.2853 - val_mae: 0.6612\n",
      "\n",
      "Epoch 00013: val_mae did not improve from 0.64554\n",
      "Epoch 14/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1145 - mae: 0.3807 - val_loss: 0.2838 - val_mae: 0.6578\n",
      "\n",
      "Epoch 00014: val_mae did not improve from 0.64554\n",
      "Epoch 15/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1136 - mae: 0.3799 - val_loss: 0.2830 - val_mae: 0.6557\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 0.64554\n",
      "Epoch 16/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1125 - mae: 0.3801 - val_loss: 0.2838 - val_mae: 0.6570\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 0.64554\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 17/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1107 - mae: 0.3766 - val_loss: 0.2803 - val_mae: 0.6517\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 0.64554\n",
      "Epoch 18/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1083 - mae: 0.3730 - val_loss: 0.2719 - val_mae: 0.6393\n",
      "\n",
      "Epoch 00018: val_mae improved from 0.64554 to 0.63935, saving model to model\\checkpoint.pt\n",
      "Epoch 19/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1045 - mae: 0.3669 - val_loss: 0.2656 - val_mae: 0.6294\n",
      "\n",
      "Epoch 00019: val_mae improved from 0.63935 to 0.62938, saving model to model\\checkpoint.pt\n",
      "Epoch 20/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0984 - mae: 0.3551 - val_loss: 0.2671 - val_mae: 0.6339\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 0.62938\n",
      "Epoch 21/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0886 - mae: 0.3340 - val_loss: 0.2593 - val_mae: 0.6322\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 0.62938\n",
      "Epoch 22/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0740 - mae: 0.2943 - val_loss: 0.2480 - val_mae: 0.6149\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.62938 to 0.61494, saving model to model\\checkpoint.pt\n",
      "Epoch 23/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0602 - mae: 0.2437 - val_loss: 0.2475 - val_mae: 0.5883\n",
      "\n",
      "Epoch 00023: val_mae improved from 0.61494 to 0.58832, saving model to model\\checkpoint.pt\n",
      "Epoch 24/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0568 - mae: 0.2316 - val_loss: 0.2713 - val_mae: 0.6082\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 0.58832\n",
      "Epoch 25/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0553 - mae: 0.2260 - val_loss: 0.2586 - val_mae: 0.6110\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 0.58832\n",
      "Epoch 26/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0542 - mae: 0.2266 - val_loss: 0.2507 - val_mae: 0.5955\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 0.58832\n",
      "Epoch 27/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0532 - mae: 0.2237 - val_loss: 0.2369 - val_mae: 0.5746\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.58832 to 0.57459, saving model to model\\checkpoint.pt\n",
      "Epoch 28/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0520 - mae: 0.2256 - val_loss: 0.2454 - val_mae: 0.5914\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 0.57459\n",
      "Epoch 29/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0504 - mae: 0.2220 - val_loss: 0.2544 - val_mae: 0.6032\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 0.57459\n",
      "Epoch 30/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0487 - mae: 0.2228 - val_loss: 0.2176 - val_mae: 0.5449\n",
      "\n",
      "Epoch 00030: val_mae improved from 0.57459 to 0.54490, saving model to model\\checkpoint.pt\n",
      "Epoch 31/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0461 - mae: 0.2193 - val_loss: 0.2144 - val_mae: 0.5416\n",
      "\n",
      "Epoch 00031: val_mae improved from 0.54490 to 0.54156, saving model to model\\checkpoint.pt\n",
      "Epoch 32/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0426 - mae: 0.2151 - val_loss: 0.2040 - val_mae: 0.5260\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.54156 to 0.52603, saving model to model\\checkpoint.pt\n",
      "Epoch 33/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0370 - mae: 0.2032 - val_loss: 0.2153 - val_mae: 0.5528\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 0.52603\n",
      "Epoch 34/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0283 - mae: 0.1810 - val_loss: 0.2104 - val_mae: 0.5429\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.52603\n",
      "Epoch 35/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0199 - mae: 0.1465 - val_loss: 0.2286 - val_mae: 0.5499\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.52603\n",
      "Epoch 36/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0175 - mae: 0.1323 - val_loss: 0.1919 - val_mae: 0.4940\n",
      "\n",
      "Epoch 00036: val_mae improved from 0.52603 to 0.49405, saving model to model\\checkpoint.pt\n",
      "Epoch 37/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0170 - mae: 0.1292 - val_loss: 0.2240 - val_mae: 0.5455\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.49405\n",
      "Epoch 38/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0165 - mae: 0.1261 - val_loss: 0.2226 - val_mae: 0.5430\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.49405\n",
      "Epoch 39/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0163 - mae: 0.1252 - val_loss: 0.1975 - val_mae: 0.5096\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.49405\n",
      "Epoch 40/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0161 - mae: 0.1230 - val_loss: 0.2155 - val_mae: 0.5401\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.49405\n",
      "Epoch 41/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0158 - mae: 0.1212 - val_loss: 0.2040 - val_mae: 0.5138\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.49405\n",
      "Epoch 42/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0156 - mae: 0.1204 - val_loss: 0.2201 - val_mae: 0.5472\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.49405\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 43/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0154 - mae: 0.1180 - val_loss: 0.2233 - val_mae: 0.5489\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.49405\n",
      "Epoch 44/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0154 - mae: 0.1181 - val_loss: 0.2053 - val_mae: 0.5258\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.49405\n",
      "Epoch 45/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0152 - mae: 0.1166 - val_loss: 0.1969 - val_mae: 0.5104\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.49405\n",
      "Epoch 46/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0151 - mae: 0.1161 - val_loss: 0.1910 - val_mae: 0.5026\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.49405\n",
      "Epoch 47/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0150 - mae: 0.1150 - val_loss: 0.2097 - val_mae: 0.5329\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.49405\n",
      "Epoch 48/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0150 - mae: 0.1149 - val_loss: 0.1831 - val_mae: 0.4943\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.49405\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 49/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0148 - mae: 0.1138 - val_loss: 0.1925 - val_mae: 0.5032\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.49405\n",
      "Epoch 50/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0147 - mae: 0.1136 - val_loss: 0.1934 - val_mae: 0.5113\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.49405\n",
      "Epoch 51/200\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.0147 - mae: 0.1133 - val_loss: 0.1926 - val_mae: 0.5083\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.49405\n",
      "Epoch 52/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0146 - mae: 0.1126 - val_loss: 0.1885 - val_mae: 0.5008\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.49405\n",
      "Epoch 53/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0145 - mae: 0.1118 - val_loss: 0.1892 - val_mae: 0.5030\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.49405\n",
      "Epoch 54/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0144 - mae: 0.1117 - val_loss: 0.1766 - val_mae: 0.4851\n",
      "\n",
      "Epoch 00054: val_mae improved from 0.49405 to 0.48515, saving model to model\\checkpoint.pt\n",
      "Epoch 55/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0144 - mae: 0.1112 - val_loss: 0.1692 - val_mae: 0.4720\n",
      "\n",
      "Epoch 00055: val_mae improved from 0.48515 to 0.47205, saving model to model\\checkpoint.pt\n",
      "Epoch 56/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0143 - mae: 0.1109 - val_loss: 0.1646 - val_mae: 0.4656\n",
      "\n",
      "Epoch 00056: val_mae improved from 0.47205 to 0.46558, saving model to model\\checkpoint.pt\n",
      "Epoch 57/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0143 - mae: 0.1108 - val_loss: 0.1697 - val_mae: 0.4729\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.46558\n",
      "Epoch 58/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0142 - mae: 0.1101 - val_loss: 0.1788 - val_mae: 0.4888\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.46558\n",
      "Epoch 59/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0142 - mae: 0.1099 - val_loss: 0.1695 - val_mae: 0.4750\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.46558\n",
      "Epoch 60/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0141 - mae: 0.1094 - val_loss: 0.1701 - val_mae: 0.4741\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.46558\n",
      "Epoch 61/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0140 - mae: 0.1091 - val_loss: 0.1576 - val_mae: 0.4565\n",
      "\n",
      "Epoch 00061: val_mae improved from 0.46558 to 0.45645, saving model to model\\checkpoint.pt\n",
      "Epoch 62/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0140 - mae: 0.1089 - val_loss: 0.1543 - val_mae: 0.4502\n",
      "\n",
      "Epoch 00062: val_mae improved from 0.45645 to 0.45017, saving model to model\\checkpoint.pt\n",
      "Epoch 63/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0139 - mae: 0.1083 - val_loss: 0.1556 - val_mae: 0.4512\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.45017\n",
      "Epoch 64/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0139 - mae: 0.1080 - val_loss: 0.1563 - val_mae: 0.4541\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.45017\n",
      "Epoch 65/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0138 - mae: 0.1078 - val_loss: 0.1628 - val_mae: 0.4640\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.45017\n",
      "Epoch 66/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0137 - mae: 0.1072 - val_loss: 0.1585 - val_mae: 0.4579\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.45017\n",
      "Epoch 67/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0137 - mae: 0.1066 - val_loss: 0.1620 - val_mae: 0.4627\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.45017\n",
      "Epoch 68/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0137 - mae: 0.1070 - val_loss: 0.1665 - val_mae: 0.4714\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.45017\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 69/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0137 - mae: 0.1070 - val_loss: 0.1599 - val_mae: 0.4605\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.45017\n",
      "Epoch 70/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0136 - mae: 0.1062 - val_loss: 0.1611 - val_mae: 0.4610\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.45017\n",
      "Epoch 71/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0135 - mae: 0.1060 - val_loss: 0.1581 - val_mae: 0.4569\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.45017\n",
      "Epoch 72/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0135 - mae: 0.1058 - val_loss: 0.1530 - val_mae: 0.4495\n",
      "\n",
      "Epoch 00072: val_mae improved from 0.45017 to 0.44952, saving model to model\\checkpoint.pt\n",
      "Epoch 73/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0135 - mae: 0.1058 - val_loss: 0.1497 - val_mae: 0.4433\n",
      "\n",
      "Epoch 00073: val_mae improved from 0.44952 to 0.44331, saving model to model\\checkpoint.pt\n",
      "Epoch 74/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0134 - mae: 0.1054 - val_loss: 0.1452 - val_mae: 0.4354\n",
      "\n",
      "Epoch 00074: val_mae improved from 0.44331 to 0.43544, saving model to model\\checkpoint.pt\n",
      "Epoch 75/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0134 - mae: 0.1050 - val_loss: 0.1518 - val_mae: 0.4469\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.43544\n",
      "Epoch 76/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0134 - mae: 0.1054 - val_loss: 0.1475 - val_mae: 0.4399\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.43544\n",
      "Epoch 77/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0133 - mae: 0.1048 - val_loss: 0.1485 - val_mae: 0.4419\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.43544\n",
      "Epoch 78/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0133 - mae: 0.1053 - val_loss: 0.1498 - val_mae: 0.4438\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.43544\n",
      "Epoch 79/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0133 - mae: 0.1050 - val_loss: 0.1429 - val_mae: 0.4324\n",
      "\n",
      "Epoch 00079: val_mae improved from 0.43544 to 0.43240, saving model to model\\checkpoint.pt\n",
      "Epoch 80/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0132 - mae: 0.1045 - val_loss: 0.1371 - val_mae: 0.4222\n",
      "\n",
      "Epoch 00080: val_mae improved from 0.43240 to 0.42218, saving model to model\\checkpoint.pt\n",
      "Epoch 81/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0132 - mae: 0.1043 - val_loss: 0.1412 - val_mae: 0.4304\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.42218\n",
      "Epoch 82/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0132 - mae: 0.1047 - val_loss: 0.1388 - val_mae: 0.4259\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.42218\n",
      "Epoch 83/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0132 - mae: 0.1043 - val_loss: 0.1403 - val_mae: 0.4280\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.42218\n",
      "Epoch 84/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0131 - mae: 0.1042 - val_loss: 0.1383 - val_mae: 0.4253\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.42218\n",
      "Epoch 85/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0131 - mae: 0.1040 - val_loss: 0.1249 - val_mae: 0.4030\n",
      "\n",
      "Epoch 00085: val_mae improved from 0.42218 to 0.40305, saving model to model\\checkpoint.pt\n",
      "Epoch 86/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0131 - mae: 0.1041 - val_loss: 0.1278 - val_mae: 0.4068\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.40305\n",
      "Epoch 87/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0130 - mae: 0.1037 - val_loss: 0.1300 - val_mae: 0.4118\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.40305\n",
      "Epoch 88/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0130 - mae: 0.1037 - val_loss: 0.1313 - val_mae: 0.4126\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.40305\n",
      "Epoch 89/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0130 - mae: 0.1038 - val_loss: 0.1253 - val_mae: 0.4042\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.40305\n",
      "Epoch 90/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0130 - mae: 0.1038 - val_loss: 0.1206 - val_mae: 0.3960\n",
      "\n",
      "Epoch 00090: val_mae improved from 0.40305 to 0.39596, saving model to model\\checkpoint.pt\n",
      "Epoch 91/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0129 - mae: 0.1034 - val_loss: 0.1240 - val_mae: 0.4007\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.39596\n",
      "Epoch 92/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0129 - mae: 0.1033 - val_loss: 0.1261 - val_mae: 0.4051\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.39596\n",
      "Epoch 93/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0128 - mae: 0.1034 - val_loss: 0.1243 - val_mae: 0.4011\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.39596\n",
      "Epoch 94/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0128 - mae: 0.1031 - val_loss: 0.1180 - val_mae: 0.3921\n",
      "\n",
      "Epoch 00094: val_mae improved from 0.39596 to 0.39205, saving model to model\\checkpoint.pt\n",
      "Epoch 95/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0128 - mae: 0.1029 - val_loss: 0.1135 - val_mae: 0.3821\n",
      "\n",
      "Epoch 00095: val_mae improved from 0.39205 to 0.38211, saving model to model\\checkpoint.pt\n",
      "Epoch 96/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0127 - mae: 0.1030 - val_loss: 0.1154 - val_mae: 0.3862\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.38211\n",
      "Epoch 97/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0127 - mae: 0.1029 - val_loss: 0.1109 - val_mae: 0.3793\n",
      "\n",
      "Epoch 00097: val_mae improved from 0.38211 to 0.37935, saving model to model\\checkpoint.pt\n",
      "Epoch 98/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0127 - mae: 0.1027 - val_loss: 0.1124 - val_mae: 0.3810\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.37935\n",
      "Epoch 99/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0126 - mae: 0.1026 - val_loss: 0.1094 - val_mae: 0.3768\n",
      "\n",
      "Epoch 00099: val_mae improved from 0.37935 to 0.37680, saving model to model\\checkpoint.pt\n",
      "Epoch 100/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0126 - mae: 0.1030 - val_loss: 0.1112 - val_mae: 0.3783\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.37680\n",
      "Epoch 101/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0126 - mae: 0.1025 - val_loss: 0.1125 - val_mae: 0.3825\n",
      "\n",
      "Epoch 00101: val_mae did not improve from 0.37680\n",
      "Epoch 102/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0125 - mae: 0.1024 - val_loss: 0.1098 - val_mae: 0.3769\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 0.37680\n",
      "Epoch 103/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0125 - mae: 0.1023 - val_loss: 0.1075 - val_mae: 0.3735\n",
      "\n",
      "Epoch 00103: val_mae improved from 0.37680 to 0.37348, saving model to model\\checkpoint.pt\n",
      "Epoch 104/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0125 - mae: 0.1023 - val_loss: 0.1005 - val_mae: 0.3607\n",
      "\n",
      "Epoch 00104: val_mae improved from 0.37348 to 0.36066, saving model to model\\checkpoint.pt\n",
      "Epoch 105/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0124 - mae: 0.1022 - val_loss: 0.1027 - val_mae: 0.3626\n",
      "\n",
      "Epoch 00105: val_mae did not improve from 0.36066\n",
      "Epoch 106/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0124 - mae: 0.1023 - val_loss: 0.0988 - val_mae: 0.3579\n",
      "\n",
      "Epoch 00106: val_mae improved from 0.36066 to 0.35787, saving model to model\\checkpoint.pt\n",
      "Epoch 107/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0123 - mae: 0.1022 - val_loss: 0.0945 - val_mae: 0.3481\n",
      "\n",
      "Epoch 00107: val_mae improved from 0.35787 to 0.34812, saving model to model\\checkpoint.pt\n",
      "Epoch 108/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0123 - mae: 0.1019 - val_loss: 0.0947 - val_mae: 0.3482\n",
      "\n",
      "Epoch 00108: val_mae did not improve from 0.34812\n",
      "Epoch 109/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0122 - mae: 0.1021 - val_loss: 0.0952 - val_mae: 0.3500\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 0.34812\n",
      "Epoch 110/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0122 - mae: 0.1020 - val_loss: 0.0966 - val_mae: 0.3515\n",
      "\n",
      "Epoch 00110: val_mae did not improve from 0.34812\n",
      "Epoch 111/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0121 - mae: 0.1020 - val_loss: 0.0917 - val_mae: 0.3442\n",
      "\n",
      "Epoch 00111: val_mae improved from 0.34812 to 0.34420, saving model to model\\checkpoint.pt\n",
      "Epoch 112/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0120 - mae: 0.1016 - val_loss: 0.0913 - val_mae: 0.3427\n",
      "\n",
      "Epoch 00112: val_mae improved from 0.34420 to 0.34268, saving model to model\\checkpoint.pt\n",
      "Epoch 113/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0120 - mae: 0.1015 - val_loss: 0.0869 - val_mae: 0.3336\n",
      "\n",
      "Epoch 00113: val_mae improved from 0.34268 to 0.33357, saving model to model\\checkpoint.pt\n",
      "Epoch 114/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0119 - mae: 0.1013 - val_loss: 0.0845 - val_mae: 0.3280\n",
      "\n",
      "Epoch 00114: val_mae improved from 0.33357 to 0.32804, saving model to model\\checkpoint.pt\n",
      "Epoch 115/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0119 - mae: 0.1014 - val_loss: 0.0851 - val_mae: 0.3305\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 0.32804\n",
      "Epoch 116/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0118 - mae: 0.1012 - val_loss: 0.0797 - val_mae: 0.3195\n",
      "\n",
      "Epoch 00116: val_mae improved from 0.32804 to 0.31949, saving model to model\\checkpoint.pt\n",
      "Epoch 117/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0117 - mae: 0.1011 - val_loss: 0.0781 - val_mae: 0.3150\n",
      "\n",
      "Epoch 00117: val_mae improved from 0.31949 to 0.31504, saving model to model\\checkpoint.pt\n",
      "Epoch 118/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0116 - mae: 0.1009 - val_loss: 0.0826 - val_mae: 0.3256\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 0.31504\n",
      "Epoch 119/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0115 - mae: 0.1007 - val_loss: 0.0784 - val_mae: 0.3170\n",
      "\n",
      "Epoch 00119: val_mae did not improve from 0.31504\n",
      "Epoch 120/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0114 - mae: 0.1011 - val_loss: 0.0776 - val_mae: 0.3151\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 0.31504\n",
      "Epoch 121/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0113 - mae: 0.1005 - val_loss: 0.0769 - val_mae: 0.3136\n",
      "\n",
      "Epoch 00121: val_mae improved from 0.31504 to 0.31364, saving model to model\\checkpoint.pt\n",
      "Epoch 122/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0111 - mae: 0.1000 - val_loss: 0.0717 - val_mae: 0.3015\n",
      "\n",
      "Epoch 00122: val_mae improved from 0.31364 to 0.30146, saving model to model\\checkpoint.pt\n",
      "Epoch 123/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0110 - mae: 0.1002 - val_loss: 0.0676 - val_mae: 0.2935\n",
      "\n",
      "Epoch 00123: val_mae improved from 0.30146 to 0.29354, saving model to model\\checkpoint.pt\n",
      "Epoch 124/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0109 - mae: 0.0995 - val_loss: 0.0713 - val_mae: 0.3013\n",
      "\n",
      "Epoch 00124: val_mae did not improve from 0.29354\n",
      "Epoch 125/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0107 - mae: 0.0990 - val_loss: 0.0664 - val_mae: 0.2906\n",
      "\n",
      "Epoch 00125: val_mae improved from 0.29354 to 0.29061, saving model to model\\checkpoint.pt\n",
      "Epoch 126/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0105 - mae: 0.0984 - val_loss: 0.0652 - val_mae: 0.2879\n",
      "\n",
      "Epoch 00126: val_mae improved from 0.29061 to 0.28792, saving model to model\\checkpoint.pt\n",
      "Epoch 127/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0102 - mae: 0.0977 - val_loss: 0.0684 - val_mae: 0.2932\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 0.28792\n",
      "Epoch 128/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0099 - mae: 0.0972 - val_loss: 0.0661 - val_mae: 0.2909\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 0.28792\n",
      "Epoch 129/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0097 - mae: 0.0963 - val_loss: 0.0689 - val_mae: 0.2984\n",
      "\n",
      "Epoch 00129: val_mae did not improve from 0.28792\n",
      "Epoch 130/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0094 - mae: 0.0956 - val_loss: 0.0679 - val_mae: 0.2999\n",
      "\n",
      "Epoch 00130: val_mae did not improve from 0.28792\n",
      "Epoch 131/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0089 - mae: 0.0940 - val_loss: 0.0642 - val_mae: 0.2918\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 0.28792\n",
      "Epoch 132/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0084 - mae: 0.0919 - val_loss: 0.0674 - val_mae: 0.3035\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 133/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0079 - mae: 0.0897 - val_loss: 0.0657 - val_mae: 0.3030\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 0.28792\n",
      "Epoch 134/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0073 - mae: 0.0873 - val_loss: 0.0776 - val_mae: 0.3367\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 0.28792\n",
      "Epoch 135/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0068 - mae: 0.0846 - val_loss: 0.0819 - val_mae: 0.3610\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 0.28792\n",
      "Epoch 136/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0061 - mae: 0.0809 - val_loss: 0.0888 - val_mae: 0.3817\n",
      "\n",
      "Epoch 00136: val_mae did not improve from 0.28792\n",
      "Epoch 137/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0054 - mae: 0.0768 - val_loss: 0.1014 - val_mae: 0.4116\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 0.28792\n",
      "Epoch 138/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0048 - mae: 0.0730 - val_loss: 0.1150 - val_mae: 0.4480\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 139/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0041 - mae: 0.0678 - val_loss: 0.1347 - val_mae: 0.4952\n",
      "\n",
      "Epoch 00139: val_mae did not improve from 0.28792\n",
      "Epoch 140/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0037 - mae: 0.0653 - val_loss: 0.1416 - val_mae: 0.5080\n",
      "\n",
      "Epoch 00140: val_mae did not improve from 0.28792\n",
      "Epoch 141/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0032 - mae: 0.0602 - val_loss: 0.1532 - val_mae: 0.5309\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 0.28792\n",
      "Epoch 142/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0029 - mae: 0.0563 - val_loss: 0.1620 - val_mae: 0.5441\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 0.28792\n",
      "Epoch 143/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0026 - mae: 0.0538 - val_loss: 0.1597 - val_mae: 0.5437\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 0.28792\n",
      "Epoch 144/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0025 - mae: 0.0523 - val_loss: 0.1764 - val_mae: 0.5692\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 145/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0023 - mae: 0.0490 - val_loss: 0.1749 - val_mae: 0.5655\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 0.28792\n",
      "Epoch 146/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0022 - mae: 0.0480 - val_loss: 0.1905 - val_mae: 0.5918\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 0.28792\n",
      "Epoch 147/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0021 - mae: 0.0469 - val_loss: 0.1968 - val_mae: 0.6047\n",
      "\n",
      "Epoch 00147: val_mae did not improve from 0.28792\n",
      "Epoch 148/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0021 - mae: 0.0468 - val_loss: 0.1872 - val_mae: 0.5892\n",
      "\n",
      "Epoch 00148: val_mae did not improve from 0.28792\n",
      "Epoch 149/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0020 - mae: 0.0453 - val_loss: 0.1992 - val_mae: 0.6075\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 0.28792\n",
      "Epoch 150/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0018 - mae: 0.0434 - val_loss: 0.2049 - val_mae: 0.6163\n",
      "\n",
      "Epoch 00150: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 151/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0018 - mae: 0.0432 - val_loss: 0.1926 - val_mae: 0.5968\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 0.28792\n",
      "Epoch 152/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0018 - mae: 0.0428 - val_loss: 0.1853 - val_mae: 0.5832\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 0.28792\n",
      "Epoch 153/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0018 - mae: 0.0431 - val_loss: 0.1967 - val_mae: 0.6028\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 0.28792\n",
      "Epoch 154/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0018 - mae: 0.0427 - val_loss: 0.2012 - val_mae: 0.6085\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 0.28792\n",
      "Epoch 155/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0018 - mae: 0.0424 - val_loss: 0.1968 - val_mae: 0.6043\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 0.28792\n",
      "Epoch 156/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0017 - mae: 0.0415 - val_loss: 0.1898 - val_mae: 0.5908\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 157/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0016 - mae: 0.0404 - val_loss: 0.2033 - val_mae: 0.6144\n",
      "\n",
      "Epoch 00157: val_mae did not improve from 0.28792\n",
      "Epoch 158/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0017 - mae: 0.0407 - val_loss: 0.1972 - val_mae: 0.6018\n",
      "\n",
      "Epoch 00158: val_mae did not improve from 0.28792\n",
      "Epoch 159/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0016 - mae: 0.0407 - val_loss: 0.2044 - val_mae: 0.6145\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 0.28792\n",
      "Epoch 160/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0016 - mae: 0.0401 - val_loss: 0.2000 - val_mae: 0.6081\n",
      "\n",
      "Epoch 00160: val_mae did not improve from 0.28792\n",
      "Epoch 161/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0016 - mae: 0.0401 - val_loss: 0.1953 - val_mae: 0.6021\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 0.28792\n",
      "Epoch 162/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0016 - mae: 0.0395 - val_loss: 0.1877 - val_mae: 0.5875\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 163/200\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.0016 - mae: 0.0395 - val_loss: 0.2035 - val_mae: 0.6126\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 0.28792\n",
      "Epoch 164/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.1981 - val_mae: 0.6058\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 0.28792\n",
      "Epoch 165/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0389 - val_loss: 0.1882 - val_mae: 0.5891\n",
      "\n",
      "Epoch 00165: val_mae did not improve from 0.28792\n",
      "Epoch 166/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0016 - mae: 0.0392 - val_loss: 0.1990 - val_mae: 0.6049\n",
      "\n",
      "Epoch 00166: val_mae did not improve from 0.28792\n",
      "Epoch 167/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0389 - val_loss: 0.1917 - val_mae: 0.5937\n",
      "\n",
      "Epoch 00167: val_mae did not improve from 0.28792\n",
      "Epoch 168/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0015 - mae: 0.0385 - val_loss: 0.1931 - val_mae: 0.5961\n",
      "\n",
      "Epoch 00168: val_mae did not improve from 0.28792\n",
      "\n",
      "Epoch 00168: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 169/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.1944 - val_mae: 0.5988\n",
      "\n",
      "Epoch 00169: val_mae did not improve from 0.28792\n",
      "Epoch 170/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0383 - val_loss: 0.1860 - val_mae: 0.5847\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 0.28792\n",
      "Epoch 171/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0015 - mae: 0.0387 - val_loss: 0.1861 - val_mae: 0.5852\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 0.28792\n",
      "Epoch 172/200\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.1873 - val_mae: 0.5876\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 0.28792\n",
      "Epoch 173/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0015 - mae: 0.0382 - val_loss: 0.1937 - val_mae: 0.5981\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 0.28792\n",
      "Epoch 174/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0015 - mae: 0.0380 - val_loss: 0.1897 - val_mae: 0.5897\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 0.28792\n",
      "Epoch 175/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.1911 - val_mae: 0.5925\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 0.28792\n",
      "Epoch 176/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0015 - mae: 0.0381 - val_loss: 0.1803 - val_mae: 0.5766\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 0.28792\n",
      "Epoch 177/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0379 - val_loss: 0.1830 - val_mae: 0.5805\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 0.28792\n",
      "Epoch 178/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0014 - mae: 0.0375 - val_loss: 0.1933 - val_mae: 0.5978\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 0.28792\n",
      "Epoch 179/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0015 - mae: 0.0376 - val_loss: 0.1891 - val_mae: 0.5918\n",
      "\n",
      "Epoch 00179: val_mae did not improve from 0.28792\n",
      "Epoch 180/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0015 - mae: 0.0392 - val_loss: 0.1762 - val_mae: 0.5702\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 0.28792\n",
      "Epoch 181/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0015 - mae: 0.0377 - val_loss: 0.1819 - val_mae: 0.5789\n",
      "\n",
      "Epoch 00181: val_mae did not improve from 0.28792\n",
      "Epoch 182/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0014 - mae: 0.0371 - val_loss: 0.1819 - val_mae: 0.5796\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 0.28792\n",
      "Epoch 183/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0014 - mae: 0.0370 - val_loss: 0.1837 - val_mae: 0.5824\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 0.28792\n",
      "Epoch 184/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.1818 - val_mae: 0.5786\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 0.28792\n",
      "Epoch 185/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0014 - mae: 0.0368 - val_loss: 0.1807 - val_mae: 0.5752\n",
      "\n",
      "Epoch 00185: val_mae did not improve from 0.28792\n",
      "Epoch 186/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0014 - mae: 0.0368 - val_loss: 0.1811 - val_mae: 0.5774\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 0.28792\n",
      "Epoch 187/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0014 - mae: 0.0364 - val_loss: 0.1770 - val_mae: 0.5705\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 0.28792\n",
      "Epoch 188/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0014 - mae: 0.0366 - val_loss: 0.1820 - val_mae: 0.5780\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 0.28792\n",
      "Epoch 189/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0014 - mae: 0.0366 - val_loss: 0.1863 - val_mae: 0.5864\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 0.28792\n",
      "Epoch 190/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0014 - mae: 0.0369 - val_loss: 0.1776 - val_mae: 0.5728\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 0.28792\n",
      "Epoch 191/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0013 - mae: 0.0360 - val_loss: 0.1803 - val_mae: 0.5769\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 0.28792\n",
      "Epoch 192/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 0.1749 - val_mae: 0.5675\n",
      "\n",
      "Epoch 00192: val_mae did not improve from 0.28792\n",
      "Epoch 193/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 0.1787 - val_mae: 0.5739\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 0.28792\n",
      "Epoch 194/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0013 - mae: 0.0361 - val_loss: 0.1738 - val_mae: 0.5665\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 0.28792\n",
      "Epoch 195/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0013 - mae: 0.0357 - val_loss: 0.1753 - val_mae: 0.5681\n",
      "\n",
      "Epoch 00195: val_mae did not improve from 0.28792\n",
      "Epoch 196/200\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0013 - mae: 0.0357 - val_loss: 0.1741 - val_mae: 0.5659\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 0.28792\n",
      "Epoch 197/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0013 - mae: 0.0354 - val_loss: 0.1773 - val_mae: 0.5727\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 0.28792\n",
      "Epoch 198/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0013 - mae: 0.0359 - val_loss: 0.1759 - val_mae: 0.5702\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 0.28792\n",
      "Epoch 199/200\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.0013 - mae: 0.0356 - val_loss: 0.1689 - val_mae: 0.5567\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 0.28792\n",
      "Epoch 200/200\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.0013 - mae: 0.0358 - val_loss: 0.1700 - val_mae: 0.5586\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 0.28792\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "checkpoint_path = \"model/checkpoint.pt\"\n",
    "\n",
    "callbacks = [\n",
    "    # EarlyStopping(monitor='val_mae', patience=7, verbose=1),\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_mae', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_mae', factor=0.8, patience=6,verbose=1,min_lr=1e-3 * 1e-1),\n",
    "    CSVLogger('./train_log.csv', separator=',', append=True),\n",
    "    ]\n",
    "\n",
    "# history = model.fit(X_train, X_train, epochs=epochs, batch_size=args.batch_size, callbacks=callbacks, validation_data=(X_validation, X_validation)).history\n",
    "history = model.fit(train_dataset, validation_data=(validation_dataset), epochs=epochs, batch_size=args.batch_size, callbacks=callbacks).history\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "model.save(\"model/model_loss_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1120x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n",
    "ax.plot(history['loss'], 'b', label='Train_loss', linewidth=2)\n",
    "ax.plot(history['val_loss'], 'r', label='Validation_loss', linewidth=2)\n",
    "ax.set_title('Model Loss', fontsize=16)\n",
    "ax.set_ylabel('loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.evaluate(test_dataset, verbose=1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_dataset)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "predict_val = model.predict(validation_dataset)\n",
    "print(predict_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.reshape(predict.shape[0], predict.shape[2])\n",
    "predict_val = predict_val.reshape(predict_val.shape[0], predict_val.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 4)\n",
      "(512, 4)\n"
     ]
    }
   ],
   "source": [
    "print(predict.shape)\n",
    "print(predict_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 4)\n"
     ]
    }
   ],
   "source": [
    "validation_data = validation_dataset.cache[0][0]\n",
    "validation_data = validation_data.reshape(validation_data.shape[0], validation_data.shape[2])\n",
    "print(validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "0.17779562164104545\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mae = np.mean(np.power(validation_data - predict_val, 2), axis=1)\n",
    "mae = np.mean(np.abs(validation_data - predict_val), axis=1)\n",
    "\n",
    "y_valid = np.ones(len(validation_data))\n",
    "\n",
    "error_df = pd.DataFrame({'Reconstruction_error':mae, 'True_class': y_valid})\n",
    "\n",
    "precision_rt, recall_rt, threshold_rt = metrics.precision_recall_curve(error_df['True_class'], error_df['Reconstruction_error'])\n",
    "\n",
    "best_cnt_dic = abs(precision_rt - recall_rt)\n",
    "threshold = threshold_rt[np.argmin(best_cnt_dic)]\n",
    "\n",
    "print(precision_rt[np.argmin(best_cnt_dic)])\n",
    "print(recall_rt[np.argmin(best_cnt_dic)])\n",
    "print(threshold)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(threshold_rt, precision_rt[1:], label='Precision')\n",
    "plt.plot(threshold_rt, recall_rt[1:], label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model/model_loss_test.h5')\n",
    "\n",
    "X_pred = model.predict(X_train)\n",
    "\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2]) \n",
    "X_pred = pd.DataFrame(X_pred)\n",
    "\n",
    "Xtrain = X_train.reshape(X_train.shape[0], X_train.shape[2]) \n",
    "\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred-Xtrain), axis=1)\n",
    "# scored['Loss_mae'] = np.mean(X_pred-Xtrain, axis=1) \n",
    "\n",
    "Threshold = 0.017\n",
    "\n",
    "plt.figure(figsize=(16,9), dpi=80)\n",
    "plt.title('Loss Distribution', fontsize=16)\n",
    "plt.xlim([0,1])\n",
    "sns.distplot(scored['Loss_mae'], kde= True, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loss_mae  Threshold  Anomaly\n",
      "0     7.677608   0.355591     True\n",
      "1     7.413066   0.355591     True\n",
      "2     7.877768   0.355591     True\n",
      "3     7.689849   0.355591     True\n",
      "4     6.997663   0.355591     True\n",
      "...        ...        ...      ...\n",
      "4091  6.016593   0.355591     True\n",
      "4092  6.173636   0.355591     True\n",
      "4093  6.350965   0.355591     True\n",
      "4094  6.216855   0.355591     True\n",
      "4095  6.222941   0.355591     True\n",
      "\n",
      "[4096 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "X_pred = pd.DataFrame(predict)\n",
    "\n",
    "scored = pd.DataFrame()\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred), axis=1)\n",
    "scored['Threshold'] = threshold*2\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "print(scored)\n",
    "\n",
    "scored.to_csv('./test_log.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.887468</td>\n",
       "      <td>7.766244</td>\n",
       "      <td>7.355838</td>\n",
       "      <td>8.700882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.567360</td>\n",
       "      <td>7.351952</td>\n",
       "      <td>7.238588</td>\n",
       "      <td>8.494366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.108690</td>\n",
       "      <td>8.104434</td>\n",
       "      <td>7.465833</td>\n",
       "      <td>8.832117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.030588</td>\n",
       "      <td>7.702415</td>\n",
       "      <td>7.265896</td>\n",
       "      <td>8.760498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.301540</td>\n",
       "      <td>6.551076</td>\n",
       "      <td>6.871746</td>\n",
       "      <td>8.266291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>3.734769</td>\n",
       "      <td>6.517411</td>\n",
       "      <td>7.404243</td>\n",
       "      <td>6.409949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>3.887559</td>\n",
       "      <td>6.651738</td>\n",
       "      <td>7.526668</td>\n",
       "      <td>6.628582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>4.520319</td>\n",
       "      <td>6.619460</td>\n",
       "      <td>7.294897</td>\n",
       "      <td>6.969188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>3.973741</td>\n",
       "      <td>6.710974</td>\n",
       "      <td>7.510346</td>\n",
       "      <td>6.672358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>3.960305</td>\n",
       "      <td>6.677608</td>\n",
       "      <td>7.546687</td>\n",
       "      <td>6.707163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4096 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     6.887468  7.766244  7.355838  8.700882\n",
       "1     6.567360  7.351952  7.238588  8.494366\n",
       "2     7.108690  8.104434  7.465833  8.832117\n",
       "3     7.030588  7.702415  7.265896  8.760498\n",
       "4     6.301540  6.551076  6.871746  8.266291\n",
       "...        ...       ...       ...       ...\n",
       "4091  3.734769  6.517411  7.404243  6.409949\n",
       "4092  3.887559  6.651738  7.526668  6.628582\n",
       "4093  4.520319  6.619460  7.294897  6.969188\n",
       "4094  3.973741  6.710974  7.510346  6.672358\n",
       "4095  3.960305  6.677608  7.546687  6.707163\n",
       "\n",
       "[4096 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loss_mae  Threshold  Anomaly\n",
      "0    0.298003   0.355591    False\n",
      "1    0.286028   0.355591    False\n",
      "2    0.252952   0.355591    False\n",
      "3    0.392858   0.355591     True\n",
      "4    0.399762   0.355591     True\n",
      "..        ...        ...      ...\n",
      "507  0.208986   0.355591    False\n",
      "508  0.259600   0.355591    False\n",
      "509  0.310010   0.355591    False\n",
      "510  0.270270   0.355591    False\n",
      "511  0.248720   0.355591    False\n",
      "\n",
      "[512 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "X_pred_val = pd.DataFrame(predict_val)\n",
    "\n",
    "scored_val = pd.DataFrame()\n",
    "scored_val['Loss_mae'] = np.mean(np.abs(X_pred_val-validation_data), axis=1)\n",
    "scored_val['Threshold'] = threshold*2\n",
    "scored_val['Anomaly'] = scored_val['Loss_mae'] > scored_val['Threshold']\n",
    "print(scored_val)\n",
    "scored_val.to_csv('./validation_log.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = model.predict(X_train)\n",
    "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
    "X_pred = pd.DataFrame(X_pred)\n",
    "\n",
    "Threshold = 0.3\n",
    "\n",
    "scored = pd.DataFrame()\n",
    "Xtest = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
    "scored['Loss_mae'] = np.mean(np.abs(X_pred), axis=1)\n",
    "scored['Threshold'] = Threshold\n",
    "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
    "print(scored)\n",
    "\n",
    "scored.to_csv('./train_log.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "606393872d2ae1b4d07a146e24c2bc65abd4ef04da8af9056b6661ebfe58ccf8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('keras')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
